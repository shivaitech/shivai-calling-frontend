import { Room, RoomEvent, Track, AudioPresets, ConnectionState } from 'livekit-client';

export interface LiveKitMessage {
  id: number;
  text: string;
  isUser: boolean;
  timestamp: Date;
  source?: 'voice' | 'chat';
}

export interface LiveKitCallbacks {
  onMessage: (message: LiveKitMessage) => void;
  onConnected: () => void;
  onDisconnected: (reason?: string) => void;
  onConnectionStateChange: (state: string) => void;
  onError: (error: string) => void;
  onStatusUpdate: (status: string, state: 'connecting' | 'connected' | 'disconnected') => void;
}

class LiveKitService {
  private room: Room | null = null;
  private isConnected: boolean = false;
  private isConnecting: boolean = false;
  private callbacks: LiveKitCallbacks | null = null;
  private lastSentMessage: string | null = null;
  private localAudioTrack: any = null;
  private remoteAudioTrack: any = null;

  // Load LiveKit SDK dynamically (EXACT match with widget.js)
  private async loadLiveKitSDK(): Promise<void> {
    return new Promise((resolve, reject) => {
      // Check if already loaded
      if ((window as any).LivekitClient !== undefined) {
        console.log('‚úÖ LiveKit already loaded');
        resolve();
        return;
      }

      console.log('üì¶ Loading LiveKit SDK...');

      // Load livekit-client directly (components-core not needed)
      const clientScript = document.createElement('script');
      clientScript.src = 'https://unpkg.com/livekit-client@latest/dist/livekit-client.umd.js';
      clientScript.onload = () => {
        console.log('‚úÖ LiveKit client loaded successfully');
        resolve();
      };
      clientScript.onerror = () => {
        console.error('‚ùå Failed to load LiveKit client');
        reject(new Error('Failed to load LiveKit client'));
      };
      document.head.appendChild(clientScript);
    });
  }

  // Initialize callbacks
  public setCallbacks(callbacks: LiveKitCallbacks): void {
    this.callbacks = callbacks;
  }

  // Connect to LiveKit room
  public async connect(agentId: string, language: string = 'en-US'): Promise<void> {
    console.log('üöÄ LiveKit Service: Starting connection process...');
    console.log('üìù Connection parameters:', { agentId, language });
    
    try {
      if (this.isConnecting || this.isConnected) {
        console.log('‚ö†Ô∏è Already connecting or connected');
        return;
      }

      console.log('üìä Initial state:', { 
        isConnecting: this.isConnecting, 
        isConnected: this.isConnected,
        hasRoom: !!this.room,
        hasCallbacks: !!this.callbacks
      });

      this.isConnecting = true;
      console.log('üîÑ Set isConnecting to true');
      this.callbacks?.onStatusUpdate('Loading LiveKit...', 'connecting');

      // Load LiveKit SDK if not available (EXACT match with widget.js)
      console.log('üîç Checking LiveKit SDK availability...');
      if ((window as any).LivekitClient === undefined) {
        console.log('üì¶ LiveKit not loaded, loading now...');
        await this.loadLiveKitSDK();
        console.log('‚úÖ LiveKit loaded successfully');
        
        // Double check after loading
        if ((window as any).LivekitClient === undefined) {
          console.error('‚ùå LiveKit still not available after loading');
          throw new Error('LiveKit not available after loading');
        }
      } else {
        console.log('‚úÖ LiveKit SDK already available');
      }

      console.log('üîç LiveKit version info:', {
        hasLiveKit: !!(window as any).LivekitClient,
        version: (window as any).LivekitClient?.version || 'unknown'
      });

      this.callbacks?.onStatusUpdate('Connecting...', 'connecting');

      // Check if connection was cancelled before token request
      if (!this.isConnecting) {
        console.log('‚ùå Connection cancelled before token request');
        return;
      }

      // Determine device type (EXACT match with widget.js)
      const deviceType = /Mobile|Android|iPhone/i.test(navigator.userAgent) ? 'mobile' : 'desktop';
      console.log('üì± Device type detected:', deviceType);

      // Get LiveKit token from backend (EXACT match with widget.js)
      const callId = `call_${Date.now()}`;
      console.log('üîë Getting token with parameters:', {
        agent_id: agentId,
        language,
        call_id: callId,
        device: deviceType,
        user_agent: navigator.userAgent
      });
      
      console.log('üåê Making request to token server...');
      const response = await fetch('https://python.service.callshivai.com/token', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({
          agent_id: agentId,
          language,
          call_id: callId,
          device: deviceType,
          user_agent: navigator.userAgent,
        }),
      });

      console.log('üì° Token server response:', {
        status: response.status,
        statusText: response.statusText,
        ok: response.ok,
        headers: Object.fromEntries(response.headers.entries())
      });

      if (!response.ok) {
        const errorText = await response.text();
        console.error('‚ùå Token server error details:', errorText);
        throw new Error(`Failed to get LiveKit token: ${response.status} - ${errorText}`);
      }

      const data = await response.json();
      console.log('‚úÖ [LiveKit] Token received successfully:', {
        hasUrl: !!data.url,
        hasToken: !!data.token,
        urlLength: data.url?.length || 0,
        tokenLength: data.token?.length || 0
      });

      // Check if connection was cancelled after getting token
      if (!this.isConnecting) {
        console.log('‚ùå Connection cancelled after token received');
        return;
      }

      // Handle any pending audio elements (for autoplay policy)
      if ((window as any).pendingAudioElement) {
        console.log('üîä Handling pending audio element...');
        (window as any).pendingAudioElement
          .play()
          .catch((err: any) => console.warn('‚ö†Ô∏è Still cannot play audio:', err));
        (window as any).pendingAudioElement = null;
      }

      // Optimized audio configuration for feedback prevention (EXACT match with widget.js)
      const audioConfig = {
        // Enhanced feedback prevention
        echoCancellation: true, // Critical for feedback prevention
        noiseSuppression: true, // Remove background noise
        autoGainControl: true, // Enable AGC for stable levels

        // Advanced feedback prevention options
        suppressLocalAudioPlayback: true, // Prevent local audio feedback

        // Constraints for user input detection
        channelCount: 1,
        sampleRate: 48000,
        sampleSize: 16,

        // Optimized volume for feedback prevention
        volume: 0.5, // Lower volume to prevent feedback
        latency: 0.1, // Slightly higher latency for stability

        // Device constraints
        facingMode: 'user',
        deviceId: 'default',

        // Browser-specific feedback prevention
        googEchoCancellation: true,
        googAutoGainControl: true, // Enable for feedback prevention
        googNoiseSuppression: true,
        googHighpassFilter: true, // Remove low frequencies that cause feedback
        googAudioMirroring: false,

        // Additional experimental options for feedback prevention
        googBeamforming: false, // Disable to prevent feedback amplification
        googArrayGeometry: false, // Disable array processing
        mozAutoGainControl: true, // Firefox feedback prevention
        mozNoiseSuppression: true,
      };

      console.log('üéµ Audio configuration prepared:', audioConfig);

      // Create LiveKit room with enhanced feedback prevention (EXACT match with widget.js)
      const LiveKit = (window as any).LivekitClient;
      console.log('üè† Creating LiveKit room...');
      
      const roomConfig = {
        adaptiveStream: true,
        dynacast: true,
        audioCaptureDefaults: {
          ...audioConfig,
          // Enhanced LiveKit feedback prevention
          echoCancellation: true,
          noiseSuppression: true,
          autoGainControl: true, // Enable for feedback prevention
          suppressLocalAudioPlayback: true, // Critical for feedback prevention
        },
        // Performance optimizations for feedback prevention
        reconnectPolicy: {
          nextRetryDelayInMs: () => 2000, // Slower reconnect to prevent issues
        },
        publishDefaults: {
          audioPreset: LiveKit.AudioPresets.speech, // Better for voice with feedback prevention
          dtx: true, // Enable discontinuous transmission
          red: false, // Disable redundancy for clarity
          simulcast: false, // Disable simulcast for voice calls
        },
        // Room options for feedback prevention
        e2eeEnabled: false,
        expWebAudioMix: false, // Disable experimental mixing that can cause feedback
      };

      console.log('üè† Room configuration:', roomConfig);
      this.room = new LiveKit.Room(roomConfig);
      console.log('‚úÖ LiveKit room created successfully');

      // Setup event listeners
      console.log('üëÇ Setting up room event listeners...');
      this.setupRoomEvents(LiveKit, audioConfig);

      // Connect to room (EXACT match with widget.js)
      console.log('üîó Connecting to LiveKit room with URL and token...');
      console.log('üîó Connection details:', {
        url: data.url,
        tokenPreview: data.token.substring(0, 20) + '...'
      });
      
      await this.room.connect(data.url, data.token);
      console.log('üîó Room connected successfully');

      // Check final connection state
      if (!this.isConnecting) {
        console.log('‚ùå Connection cancelled during room connection');
        if (this.room) {
          this.room.disconnect();
          this.room = null;
        }
        return;
      }

      console.log('üéâ Connection process completed successfully!');

    } catch (error) {
      console.error('‚ùå Connection Error:', error);
      this.isConnecting = false;
      this.isConnected = false;
      
      let errorMsg = 'Connection failed';
      if (error instanceof Error) {
        if (error.message.includes('token')) {
          errorMsg = 'Authentication failed';
        } else if (error.message.includes('timeout')) {
          errorMsg = 'Connection timeout';
        } else if (error.message.includes('network')) {
          errorMsg = 'Network error';
        }
      }
      
      this.callbacks?.onError(errorMsg);
      this.callbacks?.onStatusUpdate(`‚ùå ${errorMsg}`, 'disconnected');
    }
  }

  // Setup room event listeners
  private setupRoomEvents(LiveKit: any, audioConfig: any): void {
    if (!this.room) {
      console.error('‚ùå Cannot setup room events: room is null');
      return;
    }

    console.log('üëÇ Setting up room event listeners...');

    // ‚úÖ Track remote audio (agent speaking) with optimized settings (EXACT copy from widget.js)
    this.room.on(LiveKit.RoomEvent.TrackSubscribed, (track: any, publication: any, participant: any) => {
      console.log('üéµ TrackSubscribed event:', { 
        trackKind: track.kind, 
        participant: participant?.identity,
        trackSid: track.sid 
      });
      
      if (track.kind === LiveKit.Track.Kind.Audio) {
        console.log('üîä Audio track subscribed, setting up playback...');
        // Use audio element with feedback prevention settings
        const audioElement = track.attach();
        audioElement.volume = 0.4; // Significantly reduced to prevent feedback
        audioElement.preload = 'auto';
        audioElement.autoplay = true;

        // Add audio constraints to prevent feedback
        if (audioElement.setSinkId) {
          try {
            audioElement.setSinkId('default');
          } catch (err) {
            console.warn('‚ö†Ô∏è Could not set audio sink:', err);
          }
        }

        if (audioElement.webkitAudioDecodedByteCount !== undefined) {
          audioElement.webkitPreservesPitch = false;
        }

        document.body.appendChild(audioElement);

        audioElement.play().catch((error: any) => {
          console.warn('‚ö†Ô∏è Audio autoplay blocked, will try on user interaction:', error);
          (window as any).pendingAudioElement = audioElement;
        });

        this.remoteAudioTrack = track;
        console.log('üîä Agent audio track received with feedback prevention');
      }
    });

    // Handle participant metadata changes (EXACT copy from widget.js)
    this.room.on(LiveKit.RoomEvent.ParticipantMetadataChanged, (metadata: string, participant: any) => {
      console.log('üìã Participant metadata changed:', {
        metadata,
        participant: participant?.identity,
      });
      if (metadata) {
        try {
          const data = JSON.parse(metadata);
          if (data.transcript || data.text) {
            this.addMessage(false, data.transcript || data.text, 'voice');
            console.log('‚úÖ Transcript from participant metadata:', data.transcript || data.text);
          }
        } catch (e) {
          console.log('Metadata not JSON:', metadata);
        }
      }
    });

    // Handle room metadata changes (EXACT copy from widget.js)
    this.room.on(LiveKit.RoomEvent.RoomMetadataChanged, (metadata: string) => {
      console.log('üè† Room metadata changed:', metadata);
      if (metadata) {
        try {
          const data = JSON.parse(metadata);
          if (data.transcript || data.text) {
            this.addMessage(false, data.transcript || data.text, 'voice');
            console.log('‚úÖ Transcript from room metadata:', data.transcript || data.text);
          }
        } catch (e) {
          console.log('Room metadata not JSON:', metadata);
        }
      }
    });

    // Handle successful connection (EXACT match with widget.js)
    this.room.on(LiveKit.RoomEvent.Connected, async () => {
      console.log('üéâ Connected event fired! Room successfully connected');
      console.log('üìä Connection state after Connected event:', {
        isConnected: this.isConnected,
        isConnecting: this.isConnecting,
        roomState: this.room?.state
      });
      
      this.isConnected = true;
      this.isConnecting = false;

      console.log('üìä Updated connection state:', {
        isConnected: this.isConnected,
        isConnecting: this.isConnecting
      });

      this.callbacks?.onStatusUpdate('ü§ñ AI is Initializing...', 'connected');

      // üé§ Enable microphone with enhanced feedback prevention (EXACT match with widget.js)
      console.log('üé§ Attempting to enable microphone...');
      try {
        await this.room!.localParticipant.setMicrophoneEnabled(true, {
          // Enhanced feedback prevention
          echoCancellation: true,
          noiseSuppression: true,
          autoGainControl: true, // Enable for consistent levels and feedback prevention
          suppressLocalAudioPlayback: true, // Critical for feedback prevention

          // Stable audio settings
          channelCount: 1,
          sampleRate: 48000,
          sampleSize: 16,

          // Conservative volume to prevent feedback
          volume: 0.5, // Reduced to prevent feedback loops
          latency: 0.1, // Slightly higher for stability
          facingMode: 'user',
        });
        console.log('‚úÖ Microphone enabled with optimized settings');
      } catch (micError) {
        console.warn('‚ö†Ô∏è Failed to enable microphone with full config, trying basic:', micError);
        try {
          // Fallback to basic microphone enabling
          await this.room!.localParticipant.setMicrophoneEnabled(true);
          console.log('‚úÖ Microphone enabled (basic mode)');
        } catch (basicError) {
          console.error('‚ùå Failed to enable microphone completely:', basicError);
          this.callbacks?.onError('Failed to enable microphone. Please check your microphone permissions and try again.');
        }
      }

      // Resume audio context if suspended (browser autoplay policy) (EXACT match with widget.js)
      if ((window as any).AudioContext || (window as any).webkitAudioContext) {
        console.log('üîä Resuming audio context...');
        const AudioContextClass = (window as any).AudioContext || (window as any).webkitAudioContext;
        const audioCtx = new AudioContextClass();
        if (audioCtx.state === 'suspended') {
          audioCtx
            .resume()
            .then(() => {
              console.log('üîä Audio context resumed for better audio quality');
            })
            .catch((err: any) => console.warn('‚ö†Ô∏è Could not resume audio context:', err));
        }
      }

      this.callbacks?.onStatusUpdate('‚úÖ Connected - Speak now!', 'connected');

      // Get local audio track and start monitoring
      const audioTracks = Array.from(this.room!.localParticipant.audioTrackPublications.values());
      if (audioTracks.length > 0) {
        this.localAudioTrack = audioTracks[0].track;
        console.log('üé§ Audio track found and monitoring started immediately');
      }

      console.log('üé§ Microphone enabled and ready for conversation');
      console.log('üéâ Firing onConnected callback...');
      this.callbacks?.onConnected();
      console.log('‚úÖ Connection setup completed successfully!');
    });

    // Handle disconnection (EXACT copy from widget.js)
    this.room.on(LiveKit.RoomEvent.Disconnected, (reason: string) => {
      console.log('üî¥ Disconnected from LiveKit room:', reason);
      this.isConnected = false;
      this.callbacks?.onDisconnected(reason);
      this.callbacks?.onStatusUpdate('‚ùå Disconnected', 'disconnected');
    });

    // Handle connection state changes (EXACT copy from widget.js)
    this.room.on(LiveKit.RoomEvent.ConnectionStateChanged, (state: any) => {
      console.log('üîó Connection state changed to:', state);
      this.callbacks?.onConnectionStateChange(state);
      if (state === LiveKit.ConnectionState.Disconnected) {
        console.log('üî¥ Connection state is disconnected');
        this.isConnected = false;
        this.callbacks?.onStatusUpdate('‚ùå Disconnected', 'disconnected');
      }
    });

    // Handle data received (ENHANCED version from widget.js)
    this.room.on(LiveKit.RoomEvent.DataReceived, (payload: Uint8Array, participant: any, kind: any, topic: any) => {
      console.log('üì® DataReceived EVENT FIRED:', {
        payloadLength: payload.length,
        participant: participant?.identity,
        kind,
        topic,
        timestamp: new Date().toLocaleTimeString(),
      });

      try {
        const decoder = new TextDecoder();
        const text = decoder.decode(payload);
        console.log('üìù Raw decoded text:', text);

        // SUPER AGGRESSIVE - capture ANY text that might be a transcript (from widget.js)
        if (text && text.trim().length > 0) {
          let transcriptText = text.trim();
          let shouldAddToChat = false;
          const participantName = participant?.identity || 'Agent';

          // Skip ONLY very obvious technical messages
          const skipPatterns = ['subscribed', 'connected', 'disconnected', 'enabled', 'disabled', 'true', 'false', 'null', 'undefined'];
          const shouldSkip = skipPatterns.some(pattern => text.toLowerCase() === pattern);

          if (shouldSkip) {
            console.log('üö´ Skipping obvious technical message:', text);
            return;
          }

          console.log('üéØ Processing potential transcript:', text);

          // Try to parse as JSON first
          try {
            const jsonData = JSON.parse(text);
            console.log('üìã Parsed JSON data:', jsonData);

            // Look for ANY text field that might contain transcript
            const possibleTextFields = ['text', 'transcript', 'message', 'content', 'data', 'response', 'speech', 'voice', 'audio', 'words', 'result', 'output'];

            for (const field of possibleTextFields) {
              if (jsonData[field] && typeof jsonData[field] === 'string' && jsonData[field].trim().length > 0) {
                transcriptText = jsonData[field].trim();
                shouldAddToChat = true;
                console.log(`‚úÖ Found text in field '${field}':`, transcriptText);
                break;
              }
            }

            // Check for role information
            let isUser = false;
            if (jsonData.role) {
              isUser = jsonData.role.includes('user') || jsonData.role.includes('human');
            } else if (jsonData.speaker) {
              isUser = jsonData.speaker.includes('user') || jsonData.speaker.includes('human') || jsonData.speaker.includes('You');
            } else if (participant) {
              isUser = participant.identity === this.room!.localParticipant?.identity;
            }

            // Handle legacy transcript format
            if (jsonData.type === 'transcript' && jsonData.text) {
              if (jsonData.role === 'user') {
                // Allow voice transcripts for user, but skip chat messages
                if (jsonData.type !== 'chat') {
                  this.addMessage(true, jsonData.text, 'voice');
                } else {
                  console.log('üö´ Skipping user chat message (already shown from sendMessage)');
                }
              } else if (jsonData.role === 'assistant') {
                this.addMessage(false, jsonData.text, 'voice');
              }
              console.log('‚úÖ Processed legacy format transcript');
              return;
            }

            if (shouldAddToChat) {
              const senderRole = isUser;
              // Skip typed messages (they have source: 'typed') but allow voice transcripts
              if (!isUser || (isUser && jsonData.type !== 'chat') || (isUser && jsonData.source !== 'typed')) {
                this.addMessage(senderRole, transcriptText, 'voice');
                console.log('‚úÖ Added JSON transcript:', {
                  role: senderRole ? 'user' : 'assistant',
                  text: transcriptText.substring(0, 50) + '...',
                });
              }
            }
          } catch (e) {
            // Not JSON, treat as plain text
            console.log('üìÑ Not JSON, treating as plain text');

            // If it's reasonable length text (not just noise), add it
            if (text.length >= 2 && text.length <= 1000) {
              // Assume it's from assistant unless proven otherwise
              const isUser = participant && participant.identity === this.room!.localParticipant?.identity;

              // Add all transcripts (both user voice and assistant)
              this.addMessage(isUser, transcriptText, 'voice');
              console.log('‚úÖ Added plain text transcript:', {
                role: isUser ? 'user' : 'assistant',
                text: transcriptText.substring(0, 50) + '...',
              });
            }
          }
        }
      } catch (error) {
        console.error('‚ùå Error processing DataReceived:', error);
      }
    });

    // CRITICAL: Register text stream handlers BEFORE connecting (exactly like widget.js)
    try {
      if (typeof this.room.registerTextStreamHandler === 'function') {
        console.log('üìù Registering text stream handlers...');

        // Transcription stream
        this.room.registerTextStreamHandler('lk.transcription', async (reader: any, participantInfo: any) => {
          console.log('üéØ Transcription stream from:', participantInfo.identity);
          try {
            const info = reader.info;
            console.log('Stream info:', {
              topic: info.topic,
              id: info.id,
              timestamp: info.timestamp,
              size: info.size,
              attributes: info.attributes,
            });

            // Check if this is a final transcription
            const isFinal = info.attributes?.['lk.transcription_final'] === 'true';
            const transcribedTrackId = info.attributes?.['lk.transcribed_track_id'];
            const segmentId = info.attributes?.['lk.segment_id'];

            console.log('Transcription attributes:', {
              isFinal,
              transcribedTrackId,
              segmentId,
            });

            // Read the complete text
            const text = await reader.readAll();

            if (text && text.trim()) {
              const isUser = participantInfo.identity === this.room!.localParticipant?.identity;

              // Prevent duplicate user messages by checking against last sent message
              if (isUser && this.lastSentMessage && text.trim() === this.lastSentMessage.trim()) {
                console.log('üö´ Skipping duplicate user message from transcription:', text);
                return;
              }

              // Add transcriptions
              this.addMessage(isUser, text, 'voice');
              console.log('‚úÖ Transcription added:', {
                sender: isUser ? 'user' : 'assistant',
                text,
                isFinal,
              });
            }
          } catch (error) {
            console.error('‚ùå Error processing transcription stream:', error);
          }
        });

        // Handler for chat messages - THIS IS KEY FOR AI RESPONSES (exactly like widget.js)
        this.room.registerTextStreamHandler('lk.chat', async (reader: any, participantInfo: any) => {
          console.log('üí¨ Chat stream from:', participantInfo.identity);
          try {
            const text = await reader.readAll();
            const isUser = participantInfo.identity === this.room!.localParticipant?.identity;

            if (!isUser && text && text.trim()) {
              console.log('üí¨ AI Chat response received:', text);
              this.addMessage(false, text, 'chat');
              console.log('üí¨ Chat message added:', {
                sender: participantInfo.identity,
                text,
              });
            }
          } catch (error) {
            console.error('‚ùå Error processing chat stream:', error);
          }
        });

        console.log('‚úÖ Text stream handlers registered successfully');
      } else {
        console.warn('‚ö†Ô∏è registerTextStreamHandler not available, using fallback DataReceived');
      }
    } catch (error) {
      console.error('‚ùå Error registering text stream handlers:', error);
    }
  }

  // Add message helper
  private addMessage(isUser: boolean, text: string, source: 'voice' | 'chat' = 'voice'): void {
    if (!this.callbacks) return;

    const message: LiveKitMessage = {
      id: Date.now() + Math.random(),
      text: text.trim(),
      isUser,
      timestamp: new Date(),
      source,
    };

    this.callbacks.onMessage(message);
  }

  // Send chat message
  public async sendMessage(message: string): Promise<void> {
    if (!this.room || !this.isConnected || !message.trim()) {
      console.warn('‚ö†Ô∏è Cannot send message: not connected or empty message');
      return;
    }

    try {
      console.log('üì§ Sending chat message:', message);

      // Use LiveKit sendText method
      if (typeof this.room.localParticipant.sendText === 'function') {
        await this.room.localParticipant.sendText(message, { topic: 'lk.chat' });
        console.log('‚úÖ Chat sent with sendText');
      } else {
        // Fallback to publishData
        const chatMessage = {
          type: 'chat',
          text: message,
          timestamp: Date.now(),
          source: 'typed',
        };
        const encoder = new TextEncoder();
        const data = encoder.encode(JSON.stringify(chatMessage));
        
        this.room.localParticipant.publishData(data, { reliable: true });
        console.log('‚úÖ Chat sent with publishData');
      }

      // Add to UI immediately
      this.addMessage(true, message, 'chat');
      this.lastSentMessage = message;

    } catch (error) {
      console.error('‚ùå Error sending message:', error);
      this.callbacks?.onError('Failed to send message');
    }
  }

  // Disconnect from room
  public async disconnect(): Promise<void> {
    if (this.room) {
      this.isConnecting = false;
      this.isConnected = false;
      
      try {
        await this.room.disconnect();
        console.log('üõë Disconnected from LiveKit room');
      } catch (error) {
        console.error('‚ùå Error disconnecting:', error);
      }
      
      this.room = null;
      this.localAudioTrack = null;
      this.remoteAudioTrack = null;
    }
  }

  // Toggle microphone mute
  public async toggleMute(): Promise<boolean> {
    if (!this.room || !this.isConnected) {
      return false;
    }

    try {
      const currentState = this.room.localParticipant.isMicrophoneEnabled;
      await this.room.localParticipant.setMicrophoneEnabled(!currentState);
      console.log(`üé§ Microphone ${!currentState ? 'enabled' : 'muted'}`);
      return !currentState;
    } catch (error) {
      console.error('‚ùå Error toggling microphone:', error);
      return false;
    }
  }

  // Get connection status
  public getStatus(): { isConnected: boolean; isConnecting: boolean } {
    return {
      isConnected: this.isConnected,
      isConnecting: this.isConnecting,
    };
  }
}

export const liveKitService = new LiveKitService();